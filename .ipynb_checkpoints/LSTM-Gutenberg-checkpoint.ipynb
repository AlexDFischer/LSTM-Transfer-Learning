{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load some books from project Gutenberg into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Characters are represented by 1-hot vectors of size 128\n",
    "char_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import string\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LSTM\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file Thornton Waldo Burgess___The Adventures of Jimmy Skunk.txt\n",
      "read 86954 characters\n",
      "reading file Louisa May Alcott___Shawl-Straps.txt\n",
      "read 257608 characters\n",
      "reading file Andrew Lang___John Knox and the Reformation.txt\n",
      "read 488156 characters\n",
      "reading file Sir Richard Francis Burton___To the Gold Coast for Gold, Volume 1.txt\n",
      "read 514103 characters\n",
      "reading file Daniel Defoe___The History of the Devil.txt\n",
      "read 721216 characters\n",
      "Counter({' ': 334089, 'e': 189864, 'n': 143002, 't': 138085, 'a': 123952, 'o': 115740, 'i': 101535, 's': 95039, 'h': 93515, 'r': 91812, 'd': 63674, 'l': 61959, '\\\\': 43719, 'u': 40924, 'c': 36985, 'f': 34188, ',': 33755, 'm': 33514, 'w': 30568, 'g': 27188, 'y': 27143, 'p': 25581, 'b': 22758, 'v': 16037, '.': 14271, '_': 11357, 'k': 9653, \"'\": 7853, 'T': 5103, 'S': 4880, '-': 4789, 'I': 4730, 'A': 4378, ';': 4296, 'C': 4223, 'M': 4133, 'D': 3790, '\"': 3653, 'x': 3487, 'P': 3446, 'H': 3002, 'B': 2914, 'F': 2461, 'E': 2446, 'W': 2307, '1': 2301, 'L': 2278, 'R': 2129, 'G': 2087, 'K': 1714, '2': 1569, 'N': 1533, '5': 1501, 'O': 1487, 'q': 1430, 'J': 1346, '0': 1320, 'j': 1281, '(': 1156, ')': 1156, ':': 947, 'z': 938, '3': 900, '6': 892, '4': 854, '8': 832, '}': 822, '{': 811, '7': 728, 'V': 654, '?': 594, '9': 593, 'U': 419, '!': 412, 'Y': 370, 'Q': 361, '[': 215, ']': 215, 'X': 109, '&': 76, '/': 76, 'Z': 70, '*': 34, '|': 14, '$': 6, '=': 5, '+': 4})\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=12345)\n",
    "\n",
    "# replaces special characters with their close equivalents in order to simplify the characters that appear\n",
    "def clean_text(text):\n",
    "    return str(unicodedata.normalize('NFD', text).encode('ascii', 'ignore'))\n",
    "\n",
    "gutenberg_dir = 'Gutenberg/txt/'\n",
    "gutenberg_files = os.listdir(gutenberg_dir)\n",
    "myfiles = np.random.choice(gutenberg_files, 5)\n",
    "mystrings = []\n",
    "counters = []\n",
    "combined_counter = Counter()\n",
    "for file in myfiles:\n",
    "    print('reading file %s' % file)\n",
    "    myfile = open(gutenberg_dir + file, 'r')\n",
    "    file_text = clean_text(myfile.read())\n",
    "    print('read %d characters' % len(file_text))\n",
    "    mystrings += [file_text]\n",
    "    myfile.close()\n",
    "    counter = Counter(file_text)\n",
    "    counters += [counter]\n",
    "    combined_counter += counter\n",
    "\n",
    "print(combined_counter)\n",
    "\n",
    "for key in combined_counter.keys():\n",
    "    if ord(key) >= 128:\n",
    "        print('invalid character value found: %s has numeric value %d', key, ord(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an LSTM on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a list of N strings of length T into a numpy array of 1-hot vectors\n",
    "# input size: (N, T)\n",
    "# output size: (T, N, 128)\n",
    "i128 = np.eye(128)\n",
    "def char_to_ix(texts):\n",
    "    ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    return i128[ords].transpose((1, 0, 2))\n",
    "\n",
    "# converts a list of N strings of length T into a numpy array of length (T, N)\n",
    "def char_to_array(texts):\n",
    "    ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    return ords.transpose((1, 0))\n",
    "\n",
    "#data = char_to_ix(mystrings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_stacks):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(char_dim, hidden_dim, num_layers=num_stacks)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to character space\n",
    "        self.hidden2char = nn.Linear(hidden_dim, char_dim)\n",
    "        self.init_hidden_zeros()\n",
    "    \n",
    "    def init_hidden_zeros(self, minibatch_size):\n",
    "        self.init_hidden(torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)), torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)))\n",
    "    \n",
    "    def init_hidden(self, h, c):\n",
    "        self.hidden = (h, c)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text should be of size (T, N, char_dim)\n",
    "        # returns character scores of size (T, N, char_dim)\n",
    "        \n",
    "        hs, self.hidden = self.lstm(text, self.hidden)\n",
    "        char_space = self.hidden2char(hs)\n",
    "        return char_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(model, loss_func, data_ix, data_array):\n",
    "    model.lstm.eval()\n",
    "    model.init_hidden_zeros(data_ix.shape[1])\n",
    "    sequence_in = data_ix[:-1, :, :]\n",
    "    minibatch_size = data_ix.shape[1]\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, char_in in enumerate(sequence_in):\n",
    "            char_scores = model(char_in.view(1, minibatch_size, -1))\n",
    "            loss += loss_func(char_scores.view(-1, char_dim), data_array[i+1,:])\n",
    "    model.lstm.train()\n",
    "    return loss / len(sequence_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654427\n",
      "206804\n",
      "206806\n"
     ]
    }
   ],
   "source": [
    "# free some memory if possible\n",
    "train_data = None\n",
    "val_data = None\n",
    "test_data = None\n",
    "val_data_ix = None\n",
    "val_data_array = None\n",
    "test_data_ix = None\n",
    "test_data_array = None\n",
    "gc.collect()\n",
    "\n",
    "train_data = ''\n",
    "val_data = ''\n",
    "test_data = ''\n",
    "\n",
    "for string in mystrings:\n",
    "    train_data += string[:len(string) * 8 // 10]\n",
    "    val_data += string[len(string) * 8 // 10:len(string) * 9 // 10]\n",
    "    test_data += string[len(string) * 9 // 10:]\n",
    "\n",
    "train_data_ix = torch.tensor(char_to_ix([train_data]), dtype=torch.float)\n",
    "train_data_array = torch.tensor(char_to_array([train_data])).view(-1, 1)\n",
    "\n",
    "val_data_ix = torch.tensor(char_to_ix([val_data]), dtype=torch.float)\n",
    "val_data_array = torch.tensor(char_to_array([val_data])).view(-1, 1)\n",
    "\n",
    "test_data_ix = torch.tensor(char_to_ix([test_data]), dtype=torch.float)\n",
    "test_data_array = torch.tensor(char_to_array([test_data])).view(-1, 1)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "\n",
    "\n",
    "#train_data = mystrings[0][:90000]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#train_data_ix = torch.tensor(char_to_ix([train_data]), dtype=torch.float)\n",
    "#train_data_array = torch.tensor(char_to_array([train_data])).view(-1, 1)\n",
    "#\n",
    "#val_data = mystrings[0][-100000:-50000]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#val_data_ix = torch.tensor(char_to_ix([val_data]), dtype=torch.float)\n",
    "#val_data_array = torch.tensor(char_to_array([val_data])).view(-1, 1)\n",
    "#\n",
    "#test_data = mystrings[0][-50000:]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#test_data_ix = torch.tensor(char_to_ix([test_data]), dtype=torch.float)\n",
    "#test_data_array = torch.tensor(char_to_array([test_data])).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 0\n",
      "\ttraining loss = 4.818112\n",
      "\tvalidation loss = 4.821480\n",
      "\ton iteration 1653 / 1654\n",
      "on epoch 1\n",
      "\ttraining loss = 1.978811\n",
      "\tvalidation loss = 2.064019\n",
      "\ton iteration 1653 / 1654\n",
      "on epoch 2\n",
      "\ttraining loss = 1.870493\n",
      "\tvalidation loss = 1.954935\n",
      "\ton iteration 700 / 1654"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-06906eec1906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0msequence_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mchar_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-108-733ee93d1d9e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# returns character scores of size (T, N, char_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mchar_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#char_scores = F.log_softmax(char_space, dim=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MyLSTM(64, 3)\n",
    "#model.load_state_dict(torch.load('model_checkpoint_h100_3layer_epoch9'))\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "seq_len = 1000\n",
    "minibatch_size = 8\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    print('on epoch %d' % epoch)\n",
    "    train_loss = model_loss(model, loss_func, train_data_ix[10000:20000,:,:], train_data_array[10000:20000,:])\n",
    "    val_loss = model_loss(model, loss_func, val_data_ix[:10000,:,:], val_data_array[:10000,:])\n",
    "    print('\\ttraining loss = %f' % train_loss)\n",
    "    print('\\tvalidation loss = %f' % val_loss)\n",
    "    train_losses += [train_loss]\n",
    "    val_losses += [val_loss]\n",
    "    for i in range(len(train_data) // (seq_len * minibatch_size)):\n",
    "        print('\\r\\ton iteration %d / %d' % (i, len(train_data) // (seq_len * minibatch_size)), end='')\n",
    "        model.zero_grad()\n",
    "        model.init_hidden_zeros(minibatch_size)\n",
    "        \n",
    "        sequence_in = torch.zeros((seq_len - 1, minibatch_size, char_dim))\n",
    "        sequence_out = torch.zeros((seq_len - 1, minibatch_size))\n",
    "        for b in range(minibatch_size):\n",
    "            sequence_in[:,b,:] = train_data_ix[seq_len * (i * minibatch_size + b)\n",
    "                                               :\n",
    "                                               seq_len * (i * minibatch_size + b + 1) - 1\n",
    "                                               ,0,:\n",
    "                                              ]\n",
    "            \n",
    "            sequence_out[:,b] =  train_data_array[seq_len * (i * minibatch_size + b) + 1\n",
    "                                                  :\n",
    "                                                  seq_len * (i * minibatch_size + b + 1) \n",
    "                                                  ,0,:\n",
    "                                                 ]\n",
    "        #sequence_in = train_data_ix[seq_len * i:seq_len * (i + 1) - 1, :, :]\n",
    "        #sequence_out = train_data_array[seq_len * i + 1:seq_len * (i + 1), :]\n",
    "        \n",
    "        char_scores = model(sequence_in)\n",
    "        loss = loss_func(char_scores.view(-1, char_dim), sequence_out.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "    print()\n",
    "    torch.save(model.state_dict(), 'model_checkpoint_2_h64_3layer_epoch' + str(epoch))\n",
    "\n",
    "train_loss = model_loss(model, loss_func, train_data_ix[:100000,:,:], train_data_array[:100000,:])\n",
    "val_loss = model_loss(model, loss_func, val_data_ix, val_data_array)\n",
    "print('\\ttraining loss = %f' % train_loss)\n",
    "print('\\tvalidation loss = %f' % val_loss)\n",
    "train_losses += [train_loss]\n",
    "val_losses += [val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3714"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'my_test_model')\n",
    "model2 = MyLSTM(100)\n",
    "model2.load_state_dict(torch.load('my_test_model'))\n",
    "\n",
    "#train_loss = model_loss(model2, loss_func, train_data_ix[:50000,:,:], train_data_array[:50000,:])\n",
    "#val_loss = model_loss(model2, loss_func, val_data_ix, val_data_array)\n",
    "#print('\\ttraining loss = %f' % train_loss)\n",
    "#print('\\tvalidation loss = %f' % val_loss)\n",
    "model2 = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Anee and you will have let him goes so much of Hold to the King was a tall that I have never seen the haughance of the King, the King of Navarre, and not the first time to keep me the dead. We will be gone, and that you have been able to me you to the King of Nid-de-Merle, whom I will be a confused of the lady and force of the King of Nid-de-Merle, so dead. We will be a sort of the King father and her own priests were\\\\nhelp me to the King of Navarre and your good young horse the honour of your sa'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax()\n",
    "chars = range(128)\n",
    "\n",
    "def sample_char(char_scores, temp):\n",
    "    char_scores = softmax(char_scores / temp)\n",
    "    char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    while not chr(char) in string.printable:\n",
    "        char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    return char\n",
    "\n",
    "def sample(model, first_char, init_hidden, T, temp):\n",
    "    result = first_char\n",
    "    cur_char = ord(first_char)\n",
    "    for t in range(T):\n",
    "        one_hot_char = torch.tensor(i128[cur_char], dtype=torch.float).view(1, 1, -1)\n",
    "        char_scores = model(one_hot_char)\n",
    "        cur_char = sample_char(char_scores.view(-1), temp)\n",
    "        result += chr(cur_char)\n",
    "    return result\n",
    "\n",
    "sample(model, 'A', torch.zeros((1, 1, model.hidden_dim)), 500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
