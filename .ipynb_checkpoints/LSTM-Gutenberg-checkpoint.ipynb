{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load some books from project Gutenberg into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Characters are represented by 1-hot vectors of size 128\n",
    "char_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import string\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LSTM\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file Thornton Waldo Burgess___The Adventures of Jimmy Skunk.txt\n",
      "read 86954 characters\n",
      "reading file Louisa May Alcott___Shawl-Straps.txt\n",
      "read 257608 characters\n",
      "reading file Andrew Lang___John Knox and the Reformation.txt\n",
      "read 488156 characters\n",
      "reading file Sir Richard Francis Burton___To the Gold Coast for Gold, Volume 1.txt\n",
      "read 514103 characters\n",
      "reading file Daniel Defoe___The History of the Devil.txt\n",
      "read 721216 characters\n",
      "Counter({' ': 334089, 'e': 189864, 'n': 143002, 't': 138085, 'a': 123952, 'o': 115740, 'i': 101535, 's': 95039, 'h': 93515, 'r': 91812, 'd': 63674, 'l': 61959, '\\\\': 43719, 'u': 40924, 'c': 36985, 'f': 34188, ',': 33755, 'm': 33514, 'w': 30568, 'g': 27188, 'y': 27143, 'p': 25581, 'b': 22758, 'v': 16037, '.': 14271, '_': 11357, 'k': 9653, \"'\": 7853, 'T': 5103, 'S': 4880, '-': 4789, 'I': 4730, 'A': 4378, ';': 4296, 'C': 4223, 'M': 4133, 'D': 3790, '\"': 3653, 'x': 3487, 'P': 3446, 'H': 3002, 'B': 2914, 'F': 2461, 'E': 2446, 'W': 2307, '1': 2301, 'L': 2278, 'R': 2129, 'G': 2087, 'K': 1714, '2': 1569, 'N': 1533, '5': 1501, 'O': 1487, 'q': 1430, 'J': 1346, '0': 1320, 'j': 1281, '(': 1156, ')': 1156, ':': 947, 'z': 938, '3': 900, '6': 892, '4': 854, '8': 832, '}': 822, '{': 811, '7': 728, 'V': 654, '?': 594, '9': 593, 'U': 419, '!': 412, 'Y': 370, 'Q': 361, '[': 215, ']': 215, 'X': 109, '&': 76, '/': 76, 'Z': 70, '*': 34, '|': 14, '$': 6, '=': 5, '+': 4})\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=12345)\n",
    "\n",
    "# replaces special characters with their close equivalents in order to simplify the characters that appear\n",
    "def clean_text(text):\n",
    "    return str(unicodedata.normalize('NFD', text).encode('ascii', 'ignore'))\n",
    "\n",
    "gutenberg_dir = 'Gutenberg/txt/'\n",
    "gutenberg_files = os.listdir(gutenberg_dir)\n",
    "myfiles = np.random.choice(gutenberg_files, 5)\n",
    "mystrings = []\n",
    "counters = []\n",
    "combined_counter = Counter()\n",
    "for file in myfiles:\n",
    "    print('reading file %s' % file)\n",
    "    myfile = open(gutenberg_dir + file, 'r')\n",
    "    file_text = clean_text(myfile.read())\n",
    "    print('read %d characters' % len(file_text))\n",
    "    mystrings += [file_text]\n",
    "    myfile.close()\n",
    "    counter = Counter(file_text)\n",
    "    counters += [counter]\n",
    "    combined_counter += counter\n",
    "\n",
    "print(combined_counter)\n",
    "\n",
    "for key in combined_counter.keys():\n",
    "    if ord(key) >= 128:\n",
    "        print('invalid character value found: %s has numeric value %d', key, ord(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an LSTM on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a list of N strings of length T into a numpy array of 1-hot vectors\n",
    "# input size: (N, T)\n",
    "# output size: (T, N, 128)\n",
    "i128 = np.eye(128)\n",
    "def char_to_ix(texts):\n",
    "    ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    return i128[ords].transpose((1, 0, 2))\n",
    "\n",
    "# converts a list of N strings of length T into a numpy array of length (T, N)\n",
    "def char_to_array(texts):\n",
    "    ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    return ords.transpose((1, 0))\n",
    "\n",
    "#data = char_to_ix(mystrings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(char_dim, hidden_dim, num_layers=3, dropout=0.2)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to character space\n",
    "        self.hidden2char = nn.Linear(hidden_dim, char_dim)\n",
    "        self.init_hidden_zeros()\n",
    "    \n",
    "    def init_hidden_zeros(self):\n",
    "        self.init_hidden(torch.zeros((self.lstm.num_layers, 1, self.hidden_dim)), torch.zeros((self.lstm.num_layers, 1, self.hidden_dim)))\n",
    "    \n",
    "    def init_hidden(self, h, c):\n",
    "        self.hidden = (h, c)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text should be of size (T, N, char_dim)\n",
    "        # returns character scores of size (T, N, char_dim)\n",
    "        \n",
    "        hs, self.hidden = self.lstm(text, self.hidden)\n",
    "        char_space = self.hidden2char(hs)\n",
    "        #char_scores = F.log_softmax(char_space, dim=2)\n",
    "        return char_space#char_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(model, loss_func, data_ix, data_array):\n",
    "    model.lstm.eval()\n",
    "    model.init_hidden_zeros()\n",
    "    sequence_in = data_ix[:-1, :, :]\n",
    "    #sequence_out = data_array[1:, :]\n",
    "\n",
    "    #char_scores = model(sequence_in)\n",
    "    #loss = loss_func(char_scores.view(-1, char_dim), sequence_out.view(-1))\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, char_in in enumerate(sequence_in):\n",
    "            char_scores = model(char_in.view(1, 1, -1))\n",
    "            loss += loss_func(char_scores.view(-1, char_dim), data_array[i+1,:])\n",
    "    model.lstm.train()\n",
    "    return loss / len(sequence_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654427\n",
      "206804\n",
      "206806\n"
     ]
    }
   ],
   "source": [
    "# free some memory if possible\n",
    "train_data = None\n",
    "val_data = None\n",
    "test_data = None\n",
    "val_data_ix = None\n",
    "val_data_array = None\n",
    "test_data_ix = None\n",
    "test_data_array = None\n",
    "gc.collect()\n",
    "\n",
    "train_data = ''\n",
    "val_data = ''\n",
    "test_data = ''\n",
    "\n",
    "for string in mystrings:\n",
    "    train_data += string[:len(string) * 8 // 10]\n",
    "    val_data += string[len(string) * 8 // 10:len(string) * 9 // 10]\n",
    "    test_data += string[len(string) * 9 // 10:]\n",
    "\n",
    "train_data_ix = torch.tensor(char_to_ix([train_data]), dtype=torch.float)\n",
    "train_data_array = torch.tensor(char_to_array([train_data])).view(-1, 1)\n",
    "\n",
    "val_data_ix = torch.tensor(char_to_ix([val_data]), dtype=torch.float)\n",
    "val_data_array = torch.tensor(char_to_array([val_data])).view(-1, 1)\n",
    "\n",
    "test_data_ix = torch.tensor(char_to_ix([test_data]), dtype=torch.float)\n",
    "test_data_array = torch.tensor(char_to_array([test_data])).view(-1, 1)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "\n",
    "\n",
    "#train_data = mystrings[0][:90000]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#train_data_ix = torch.tensor(char_to_ix([train_data]), dtype=torch.float)\n",
    "#train_data_array = torch.tensor(char_to_array([train_data])).view(-1, 1)\n",
    "#\n",
    "#val_data = mystrings[0][-100000:-50000]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#val_data_ix = torch.tensor(char_to_ix([val_data]), dtype=torch.float)\n",
    "#val_data_array = torch.tensor(char_to_array([val_data])).view(-1, 1)\n",
    "#\n",
    "#test_data = mystrings[0][-50000:]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#test_data_ix = torch.tensor(char_to_ix([test_data]), dtype=torch.float)\n",
    "#test_data_array = torch.tensor(char_to_array([test_data])).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 0\n",
      "\ttraining loss = 1.591293\n",
      "\tvalidation loss = 1.673396\n",
      "on epoch 1\n",
      "\ttraining loss = 1.550634\n",
      "\tvalidation loss = 1.667238\n",
      "on epoch 2\n",
      "\ttraining loss = 1.559596\n",
      "\tvalidation loss = 1.655922\n",
      "on epoch 3\n",
      "\ttraining loss = 1.551050\n",
      "\tvalidation loss = 1.664115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-a569bdfbfd72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mchar_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MyLSTM(100)\n",
    "model.load_state_dict(torch.load('model_checkpoint_h100_3layer_epoch9'))\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "seq_len = 1000\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    print('on epoch %d' % epoch)\n",
    "    train_loss = model_loss(model, loss_func, train_data_ix[10000:20000,:,:], train_data_array[10000:20000,:])\n",
    "    val_loss = model_loss(model, loss_func, val_data_ix[:10000,:,:], val_data_array[:10000,:])\n",
    "    print('\\ttraining loss = %f' % train_loss)\n",
    "    print('\\tvalidation loss = %f' % val_loss)\n",
    "    train_losses += [train_loss]\n",
    "    val_losses += [val_loss]\n",
    "    for i in range(len(train_data) // seq_len):\n",
    "        model.zero_grad()\n",
    "        model.init_hidden_zeros()\n",
    "        \n",
    "        sequence_in = train_data_ix[seq_len * i:seq_len * (i + 1) - 1, :, :]\n",
    "        sequence_out = train_data_array[seq_len * i + 1:seq_len * (i + 1), :]\n",
    "        \n",
    "        char_scores = model(sequence_in)\n",
    "        loss = loss_func(char_scores.view(-1, char_dim), sequence_out.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "    torch.save(model.state_dict(), 'model_checkpoint_2_h100_3layer_epoch' + str(epoch))\n",
    "\n",
    "train_loss = model_loss(model, loss_func, train_data_ix[:100000,:,:], train_data_array[:100000,:])\n",
    "val_loss = model_loss(model, loss_func, val_data_ix, val_data_array)\n",
    "print('\\ttraining loss = %f' % train_loss)\n",
    "print('\\tvalidation loss = %f' % val_loss)\n",
    "train_losses += [train_loss]\n",
    "val_losses += [val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3714"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'my_test_model')\n",
    "model2 = MyLSTM(100)\n",
    "model2.load_state_dict(torch.load('my_test_model'))\n",
    "\n",
    "#train_loss = model_loss(model2, loss_func, train_data_ix[:50000,:,:], train_data_array[:50000,:])\n",
    "#val_loss = model_loss(model2, loss_func, val_data_ix, val_data_array)\n",
    "#print('\\ttraining loss = %f' % train_loss)\n",
    "#print('\\tvalidation loss = %f' % val_loss)\n",
    "model2 = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Anee and you will have let him goes so much of Hold to the King was a tall that I have never seen the haughance of the King, the King of Navarre, and not the first time to keep me the dead. We will be gone, and that you have been able to me you to the King of Nid-de-Merle, whom I will be a confused of the lady and force of the King of Nid-de-Merle, so dead. We will be a sort of the King father and her own priests were\\\\nhelp me to the King of Navarre and your good young horse the honour of your sa'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax()\n",
    "chars = range(128)\n",
    "\n",
    "def sample_char(char_scores, temp):\n",
    "    char_scores = softmax(char_scores / temp)\n",
    "    char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    while not chr(char) in string.printable:\n",
    "        char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    return char\n",
    "\n",
    "def sample(model, first_char, init_hidden, T, temp):\n",
    "    result = first_char\n",
    "    cur_char = ord(first_char)\n",
    "    for t in range(T):\n",
    "        one_hot_char = torch.tensor(i128[cur_char], dtype=torch.float).view(1, 1, -1)\n",
    "        char_scores = model(one_hot_char)\n",
    "        cur_char = sample_char(char_scores.view(-1), temp)\n",
    "        result += chr(cur_char)\n",
    "    return result\n",
    "\n",
    "sample(model, 'A', torch.zeros((1, 1, model.hidden_dim)), 500, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
