{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load some books from project Gutenberg into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Characters are represented by 1-hot vectors of size 128\n",
    "char_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import string\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LSTM\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file Thornton Waldo Burgess___The Adventures of Jimmy Skunk.txt\n",
      "read 85169 characters\n",
      "reading file Louisa May Alcott___Shawl-Straps.txt\n",
      "read 252723 characters\n",
      "reading file Andrew Lang___John Knox and the Reformation.txt\n",
      "read 479775 characters\n",
      "reading file Sir Richard Francis Burton___To the Gold Coast for Gold, Volume 1.txt\n",
      "read 505753 characters\n",
      "reading file Daniel Defoe___The History of the Devil.txt\n",
      "read 708741 characters\n",
      "Counter({' ': 334089, 'e': 189864, 't': 138085, 'a': 123952, 'o': 115740, 'n': 107126, 'i': 101535, 's': 95039, 'h': 93515, 'r': 91812, 'd': 63674, 'l': 61959, 'u': 40924, 'c': 36985, '\\n': 35876, 'f': 34188, ',': 33755, 'm': 33514, 'w': 30568, 'g': 27188, 'y': 27143, 'p': 25581, 'b': 22758, 'v': 16037, '.': 14271, '_': 11357, 'k': 9653, \"'\": 7853, '\\\\': 7843, 'T': 5103, 'S': 4880, '-': 4789, 'I': 4730, 'A': 4378, ';': 4296, 'C': 4223, 'M': 4133, 'D': 3790, '\"': 3653, 'x': 3487, 'P': 3446, 'H': 3002, 'B': 2914, 'F': 2461, 'E': 2446, 'W': 2307, '1': 2301, 'L': 2278, 'R': 2129, 'G': 2087, 'K': 1714, '2': 1569, 'N': 1533, '5': 1501, 'O': 1487, 'q': 1430, 'J': 1346, '0': 1320, 'j': 1281, '(': 1156, ')': 1156, ':': 947, 'z': 938, '3': 900, '6': 892, '4': 854, '8': 832, '}': 822, '{': 811, '7': 728, 'V': 654, '?': 594, '9': 593, 'U': 419, '!': 412, 'Y': 370, 'Q': 361, '[': 215, ']': 215, 'X': 109, '&': 76, '/': 76, 'Z': 70, '*': 34, '|': 14, '$': 6, '=': 5, '+': 4})\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=12345)\n",
    "\n",
    "# replaces special characters with their close equivalents in order to simplify the characters that appear\n",
    "def clean_text(text):\n",
    "    return str(unicodedata.normalize('NFD', text).encode('ascii', 'ignore')).replace('\\\\n', '\\n')\n",
    "\n",
    "gutenberg_dir = 'Gutenberg/txt/'\n",
    "gutenberg_files = os.listdir(gutenberg_dir)\n",
    "myfiles = np.random.choice(gutenberg_files, 5)\n",
    "mystrings = []\n",
    "counters = []\n",
    "combined_counter = Counter()\n",
    "for file in myfiles:\n",
    "    print('reading file %s' % file)\n",
    "    myfile = open(gutenberg_dir + file, 'r')\n",
    "    file_text = clean_text(myfile.read())\n",
    "    print('read %d characters' % len(file_text))\n",
    "    mystrings += [file_text]\n",
    "    myfile.close()\n",
    "    counter = Counter(file_text)\n",
    "    counters += [counter]\n",
    "    combined_counter += counter\n",
    "\n",
    "print(combined_counter)\n",
    "\n",
    "for key in combined_counter.keys():\n",
    "    if ord(key) >= 128:\n",
    "        print('invalid character value found: %s has numeric value %d', key, ord(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an LSTM on this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a list of N strings of length T into a numpy array of 1-hot vectors\n",
    "# input size: (N, T)\n",
    "# output size: (T, N, 128)\n",
    "i128 = np.eye(128)\n",
    "def char_to_ix(texts):\n",
    "    ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    return i128[ords].transpose((1, 0, 2))\n",
    "\n",
    "# converts a list of N strings of length T into a numpy array of length (T, N)\n",
    "def char_to_array(texts):\n",
    "    ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    return ords.transpose((1, 0))\n",
    "\n",
    "#data = char_to_ix(mystrings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_stacks):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(char_dim, hidden_dim, num_layers=num_stacks)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to character space\n",
    "        self.hidden2char = nn.Linear(hidden_dim, char_dim)\n",
    "        self.init_hidden_zeros(1)\n",
    "    \n",
    "    def init_hidden_zeros(self, minibatch_size):\n",
    "        self.init_hidden(torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)), torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)))\n",
    "    \n",
    "    def init_hidden(self, h, c):\n",
    "        self.hidden = (h, c)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text should be of size (T, N, char_dim)\n",
    "        # returns character scores of size (T, N, char_dim)\n",
    "        \n",
    "        hs, self.hidden = self.lstm(text, self.hidden)\n",
    "        char_space = self.hidden2char(hs)\n",
    "        return char_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(model, loss_func, data_ix, data_array):\n",
    "    model.lstm.eval()\n",
    "    model.init_hidden_zeros(data_ix.shape[1])\n",
    "    sequence_in = data_ix[:-1, :, :]\n",
    "    minibatch_size = data_ix.shape[1]\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, char_in in enumerate(sequence_in):\n",
    "            char_scores = model(char_in.view(1, minibatch_size, -1))\n",
    "            loss += loss_func(char_scores.view(-1, char_dim), data_array[i+1,:])\n",
    "    model.lstm.train()\n",
    "    return loss / len(sequence_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1625727\n",
      "203215\n",
      "203219\n"
     ]
    }
   ],
   "source": [
    "# free some memory if possible\n",
    "train_data = None\n",
    "val_data = None\n",
    "test_data = None\n",
    "val_data_ix = None\n",
    "val_data_array = None\n",
    "test_data_ix = None\n",
    "test_data_array = None\n",
    "gc.collect()\n",
    "\n",
    "train_data = ''\n",
    "val_data = ''\n",
    "test_data = ''\n",
    "\n",
    "for string in mystrings:\n",
    "    train_data += string[:len(string) * 8 // 10]\n",
    "    val_data += string[len(string) * 8 // 10:len(string) * 9 // 10]\n",
    "    test_data += string[len(string) * 9 // 10:]\n",
    "\n",
    "train_data_ix = torch.tensor(char_to_ix([train_data]), dtype=torch.float)\n",
    "train_data_array = torch.tensor(char_to_array([train_data])).view(-1, 1)\n",
    "\n",
    "val_data_ix = torch.tensor(char_to_ix([val_data]), dtype=torch.float)\n",
    "val_data_array = torch.tensor(char_to_array([val_data])).view(-1, 1)\n",
    "\n",
    "test_data_ix = torch.tensor(char_to_ix([test_data]), dtype=torch.float)\n",
    "test_data_array = torch.tensor(char_to_array([test_data])).view(-1, 1)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))\n",
    "\n",
    "\n",
    "#train_data = mystrings[0][:90000]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#train_data_ix = torch.tensor(char_to_ix([train_data]), dtype=torch.float)\n",
    "#train_data_array = torch.tensor(char_to_array([train_data])).view(-1, 1)\n",
    "#\n",
    "#val_data = mystrings[0][-100000:-50000]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#val_data_ix = torch.tensor(char_to_ix([val_data]), dtype=torch.float)\n",
    "#val_data_array = torch.tensor(char_to_array([val_data])).view(-1, 1)\n",
    "#\n",
    "#test_data = mystrings[0][-50000:]\n",
    "#\n",
    "## data_ix is of shape (T, N, char_dim) while data_array is of shape (T, N)\n",
    "#test_data_ix = torch.tensor(char_to_ix([test_data]), dtype=torch.float)\n",
    "#test_data_array = torch.tensor(char_to_array([test_data])).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 0\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 2.926826\n",
      "\tvalidation loss = 3.020272\n",
      "on epoch 1\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 2.611279\n",
      "\tvalidation loss = 2.699909\n",
      "on epoch 2\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 2.429155\n",
      "\tvalidation loss = 2.496237\n",
      "on epoch 3\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 2.287392\n",
      "\tvalidation loss = 2.345573\n",
      "on epoch 4\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 2.163868\n",
      "\tvalidation loss = 2.234972\n",
      "on epoch 5\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 2.082817\n",
      "\tvalidation loss = 2.152047\n",
      "on epoch 6\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 2.011992\n",
      "\tvalidation loss = 2.098860\n",
      "on epoch 7\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.974913\n",
      "\tvalidation loss = 2.069597\n",
      "on epoch 8\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.933031\n",
      "\tvalidation loss = 2.033798\n",
      "on epoch 9\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.900370\n",
      "\tvalidation loss = 1.996491\n",
      "on epoch 10\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.864673\n",
      "\tvalidation loss = 1.963744\n",
      "on epoch 11\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.830863\n",
      "\tvalidation loss = 1.920153\n",
      "on epoch 12\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.818529\n",
      "\tvalidation loss = 1.903370\n",
      "on epoch 13\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.790296\n",
      "\tvalidation loss = 1.877419\n",
      "on epoch 14\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.768980\n",
      "\tvalidation loss = 1.861070\n",
      "on epoch 15\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.754502\n",
      "\tvalidation loss = 1.838344\n",
      "on epoch 16\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.731806\n",
      "\tvalidation loss = 1.817453\n",
      "on epoch 17\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.714126\n",
      "\tvalidation loss = 1.796759\n",
      "on epoch 18\n",
      "\ton iteration 100 / 101\n",
      "\ttraining loss = 1.693878\n",
      "\tvalidation loss = 1.784606\n",
      "on epoch 19\n",
      "\ton iteration 21 / 101"
     ]
    }
   ],
   "source": [
    "model = MyLSTM(64, 3)\n",
    "model.lstm.dropout=0.2\n",
    "#model.load_state_dict(torch.load('model_checkpoint_h100_3layer_epoch9'))\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "seq_len = 1000\n",
    "minibatch_size = 16\n",
    "\n",
    "train_losses_dropout = []\n",
    "val_losses_dropout = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    print('on epoch %d' % epoch)\n",
    "    for i in range(len(train_data) // (seq_len * minibatch_size)):\n",
    "        print('\\r\\ton iteration %d / %d' % (i, len(train_data) // (seq_len * minibatch_size)), end='')\n",
    "        model.zero_grad()\n",
    "        model.init_hidden_zeros(minibatch_size)\n",
    "        \n",
    "        sequence_in = torch.zeros((seq_len - 1, minibatch_size, char_dim))\n",
    "        sequence_out = torch.zeros((seq_len - 1, minibatch_size), dtype=torch.long)\n",
    "        for b in range(minibatch_size):\n",
    "            sequence_in[:,b,:] = train_data_ix[seq_len * (i * minibatch_size + b)\n",
    "                                               :\n",
    "                                               seq_len * (i * minibatch_size + b + 1) - 1\n",
    "                                               ,0,:\n",
    "                                              ]\n",
    "            \n",
    "            sequence_out[:,b] =  train_data_array[seq_len * (i * minibatch_size + b) + 1\n",
    "                                                  :\n",
    "                                                  seq_len * (i * minibatch_size + b + 1) \n",
    "                                                  ,0\n",
    "                                                 ]\n",
    "        #sequence_in = train_data_ix[seq_len * i:seq_len * (i + 1) - 1, :, :]\n",
    "        #sequence_out = train_data_array[seq_len * i + 1:seq_len * (i + 1), :]\n",
    "        \n",
    "        char_scores = model(sequence_in)\n",
    "        loss = loss_func(char_scores.view(-1, char_dim), sequence_out.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "    print()\n",
    "    train_loss = model_loss(model, loss_func, train_data_ix[10000:20000,:,:], train_data_array[10000:20000,:])\n",
    "    val_loss = model_loss(model, loss_func, val_data_ix[:10000,:,:], val_data_array[:10000,:])\n",
    "    print('\\ttraining loss = %f' % train_loss)\n",
    "    print('\\tvalidation loss = %f' % val_loss)\n",
    "    train_losses_dropout += [train_loss]\n",
    "    val_losses_dropout += [val_loss]\n",
    "    torch.save(model.state_dict(), 'model_checkpoint_2_h64_3layer_dropout_epoch' + str(epoch))\n",
    "\n",
    "train_loss = model_loss(model, loss_func, train_data_ix[:100000,:,:], train_data_array[:100000,:])\n",
    "val_loss = model_loss(model, loss_func, val_data_ix, val_data_array)\n",
    "print('\\ttraining loss = %f' % train_loss)\n",
    "print('\\tvalidation loss = %f' % val_loss)\n",
    "train_losses_dropout += [train_loss]\n",
    "val_losses_dropout += [val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 0\n",
      "\ton iteration 2 / 101"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-931b6e4cf6a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#sequence_out = train_data_array[seq_len * i + 1:seq_len * (i + 1), :]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mchar_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cfc0225e0f50>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# returns character scores of size (T, N, char_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mchar_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchar_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = MyLSTM(64, 3)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "seq_len = 1000\n",
    "minibatch_size = 16\n",
    "\n",
    "train_losses_h64_l3 = []\n",
    "val_losses_h64_l3 = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('on epoch %d' % epoch)\n",
    "    for i in range(len(train_data) // (seq_len * minibatch_size)):\n",
    "        print('\\r\\ton iteration %d / %d' % (i, len(train_data) // (seq_len * minibatch_size)), end='')\n",
    "        model.zero_grad()\n",
    "        model.init_hidden_zeros(minibatch_size)\n",
    "        \n",
    "        sequence_in = torch.zeros((seq_len - 1, minibatch_size, char_dim))\n",
    "        sequence_out = torch.zeros((seq_len - 1, minibatch_size), dtype=torch.long)\n",
    "        for b in range(minibatch_size):\n",
    "            sequence_in[:,b,:] = train_data_ix[seq_len * (i * minibatch_size + b)\n",
    "                                               :\n",
    "                                               seq_len * (i * minibatch_size + b + 1) - 1\n",
    "                                               ,0,:\n",
    "                                              ]\n",
    "            \n",
    "            sequence_out[:,b] =  train_data_array[seq_len * (i * minibatch_size + b) + 1\n",
    "                                                  :\n",
    "                                                  seq_len * (i * minibatch_size + b + 1) \n",
    "                                                  ,0\n",
    "                                                 ]\n",
    "        #sequence_in = train_data_ix[seq_len * i:seq_len * (i + 1) - 1, :, :]\n",
    "        #sequence_out = train_data_array[seq_len * i + 1:seq_len * (i + 1), :]\n",
    "        \n",
    "        char_scores = model(sequence_in)\n",
    "        loss = loss_func(char_scores.view(-1, char_dim), sequence_out.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "    print()\n",
    "    train_loss = model_loss(model, loss_func, train_data_ix[10000:20000,:,:], train_data_array[10000:20000,:])\n",
    "    val_loss = model_loss(model, loss_func, val_data_ix[:10000,:,:], val_data_array[:10000,:])\n",
    "    print('\\ttraining loss = %f' % train_loss)\n",
    "    print('\\tvalidation loss = %f' % val_loss)\n",
    "    train_losses_h64_l3 += [train_loss]\n",
    "    val_losses_h64_l3 += [val_loss]\n",
    "    torch.save(model.state_dict(), 'model_checkpoint_2_h64_3layer_epoch' + str(epoch))\n",
    "\n",
    "train_loss = model_loss(model, loss_func, train_data_ix[:100000,:,:], train_data_array[:100000,:])\n",
    "val_loss = model_loss(model, loss_func, val_data_ix, val_data_array)\n",
    "print('training loss = %f' % train_loss)\n",
    "print('validation loss = %f' % val_loss)\n",
    "train_losses_h64_l3 += [train_loss]\n",
    "val_losses_h64_l3 += [val_loss]\n",
    "\n",
    "#################################\n",
    "\n",
    "model = MyLSTM(64, 2)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.01)\n",
    "seq_len = 1000\n",
    "minibatch_size = 16\n",
    "\n",
    "train_losses_h64_l2 = []\n",
    "val_losses_h64_l2 = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('on epoch %d' % epoch)\n",
    "    for i in range(len(train_data) // (seq_len * minibatch_size)):\n",
    "        print('\\r\\ton iteration %d / %d' % (i, len(train_data) // (seq_len * minibatch_size)), end='')\n",
    "        model.zero_grad()\n",
    "        model.init_hidden_zeros(minibatch_size)\n",
    "        \n",
    "        sequence_in = torch.zeros((seq_len - 1, minibatch_size, char_dim))\n",
    "        sequence_out = torch.zeros((seq_len - 1, minibatch_size), dtype=torch.long)\n",
    "        for b in range(minibatch_size):\n",
    "            sequence_in[:,b,:] = train_data_ix[seq_len * (i * minibatch_size + b)\n",
    "                                               :\n",
    "                                               seq_len * (i * minibatch_size + b + 1) - 1\n",
    "                                               ,0,:\n",
    "                                              ]\n",
    "            \n",
    "            sequence_out[:,b] =  train_data_array[seq_len * (i * minibatch_size + b) + 1\n",
    "                                                  :\n",
    "                                                  seq_len * (i * minibatch_size + b + 1) \n",
    "                                                  ,0\n",
    "                                                 ]\n",
    "        #sequence_in = train_data_ix[seq_len * i:seq_len * (i + 1) - 1, :, :]\n",
    "        #sequence_out = train_data_array[seq_len * i + 1:seq_len * (i + 1), :]\n",
    "        \n",
    "        char_scores = model(sequence_in)\n",
    "        loss = loss_func(char_scores.view(-1, char_dim), sequence_out.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "    print()\n",
    "    train_loss = model_loss(model, loss_func, train_data_ix[10000:20000,:,:], train_data_array[10000:20000,:])\n",
    "    val_loss = model_loss(model, loss_func, val_data_ix[:10000,:,:], val_data_array[:10000,:])\n",
    "    print('\\ttraining loss = %f' % train_loss)\n",
    "    print('\\tvalidation loss = %f' % val_loss)\n",
    "    train_losses_h64_l2 += [train_loss]\n",
    "    val_losses_h64_l2 += [val_loss]\n",
    "    torch.save(model.state_dict(), 'model_checkpoint_2_h64_2layer_epoch' + str(epoch))\n",
    "\n",
    "train_loss = model_loss(model, loss_func, train_data_ix[:100000,:,:], train_data_array[:100000,:])\n",
    "val_loss = model_loss(model, loss_func, val_data_ix, val_data_array)\n",
    "print('training loss = %f' % train_loss)\n",
    "print('validation loss = %f' % val_loss)\n",
    "train_losses_h64_l2 += [train_loss]\n",
    "val_losses_h64_l2 += [val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum validation loss wsa 1.510688 at epoch 92\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(100)\n",
    "plt.plot(x, train_losses_h64_l3[:-1], label='training loss')\n",
    "plt.plot(x, val_losses_h64_l3[:-1], label='validation loss')\n",
    "print('minimum validation loss wsa %f at epoch %d' % (np.min(val_losses_h64_l3), np.argmin(val_losses_h64_l3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = MyLSTM(64, 3)\n",
    "best_model.load_state_dict(torch.load('model_checkpoint_2_h64_3layer_epoch50'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEr or a Portugueses and selding in the Proper Word, and the _Devil_ to act the Disguise, and he think his Spirit is the _Devil_ has been explain in all the Appearance and proverb to enquire up as him to make a Committen of _Devils_, who would be known a Command, the _Devil_\n",
      "of the Performing to the World.\n",
      "\n",
      "The Story of the Discomet as a great Devil was to our old _Devil_, that they for the World but what he had not to be according to it as to come out of the fair _Devil_ in the Side, and the \n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax()\n",
    "chars = range(128)\n",
    "\n",
    "def sample_char(char_scores, temp):\n",
    "    char_scores = softmax(char_scores / temp)\n",
    "    char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    while not chr(char) in string.printable:\n",
    "        char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    return char\n",
    "\n",
    "def sample(model, first_char, init_hidden, T, temp):\n",
    "    result = first_char\n",
    "    cur_char = ord(first_char)\n",
    "    for t in range(T):\n",
    "        one_hot_char = torch.tensor(i128[cur_char], dtype=torch.float).view(1, 1, -1)\n",
    "        char_scores = model(one_hot_char)\n",
    "        cur_char = sample_char(char_scores.view(-1), temp)\n",
    "        result += chr(cur_char)\n",
    "    return result.replace('\\\\n', '\\n') # I messed up the encoding of newliens\n",
    "\n",
    "print(sample(best_model, 'T', torch.zeros((1, 1, model.hidden_dim)), 500, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
