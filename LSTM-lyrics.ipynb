{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Characters are represented by 1-hot vectors of size 128\n",
    "char_dim = 128\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import string\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LSTM\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 57471\n",
      "training songs:   51724\n",
      "validation songs: 2873\n",
      "test songs:       2874\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "songfile = open('songdata.csv', 'r')\n",
    "songfile.readline()\n",
    "csvreader = csv.reader(songfile, delimiter=',')\n",
    "count = 0\n",
    "while True:\n",
    "    try:\n",
    "        csvreader.__next__()\n",
    "        count += 1\n",
    "    except StopIteration:\n",
    "        break\n",
    "songfile.close()\n",
    "print('count = %d' % count)\n",
    "\n",
    "# randomly assign songs to train, val, and test files\n",
    "perm = np.random.permutation(count)\n",
    "songfile = open('songdata.csv', 'r')\n",
    "songfile.readline()\n",
    "csvreader = csv.reader(songfile, delimiter=',')\n",
    "\n",
    "train_file = open('songdata_train.csv', 'w')\n",
    "val_file = open('songdata_val.csv', 'w')\n",
    "test_file = open('songdata_test.csv', 'w')\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "test_count = 0\n",
    "train_writer = csv.writer(train_file)\n",
    "val_writer = csv.writer(val_file)\n",
    "test_writer = csv.writer(test_file)\n",
    "for i, row in enumerate(csvreader):\n",
    "    if perm[i] < count * 5 // 100:\n",
    "        val_writer.writerow(row)\n",
    "        val_count += 1\n",
    "    elif perm[i] < count * 10 // 100:\n",
    "        test_writer.writerow(row)\n",
    "        test_count += 1\n",
    "    else:\n",
    "        train_writer.writerow(row)\n",
    "        train_count += 1\n",
    "train_file.close()\n",
    "val_file.close()\n",
    "test_file.close()\n",
    "songfile.close()\n",
    "\n",
    "print('training songs:   %d' % train_count)\n",
    "print('validation songs: %d' % val_count)\n",
    "print('test songs:       %d' % test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a list of N strings of length <=T into a numpy array of 1-hot vectors\n",
    "# input: list of length N; max length of any string in the list is T\n",
    "# output size: (T, N, 128)\n",
    "i128 = np.eye(128)\n",
    "def char_to_ix(texts):\n",
    "    T = max([len(text) for text in texts])\n",
    "    ords = np.zeros((T, len(texts)), dtype=int)\n",
    "    for n, text in enumerate(texts):\n",
    "        ords[:len(text), n] = [ord(char) for char in text]\n",
    "    return i128[ords]\n",
    "\n",
    "# converts a list of N strings of length <=T into a numpy array of length (T, N).\n",
    "# Zero-pads shorter strings.\n",
    "def char_to_array(texts):\n",
    "    T = max([len(text) for text in texts])\n",
    "    result = np.zeros((T, len(texts)), dtype=int)\n",
    "    for n, text in enumerate(texts):\n",
    "        result[:len(text), n] = [ord(char) for char in text]\n",
    "    return result\n",
    "    #ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    #return ords.transpose((1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_stacks):\n",
    "        super(LyricsLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(char_dim, hidden_dim, num_layers=num_stacks, dropout=0.0)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to character space\n",
    "        self.hidden2char = nn.Linear(hidden_dim, char_dim)\n",
    "        self.init_hidden_zeros(1)\n",
    "    \n",
    "    def init_hidden_zeros(self, minibatch_size):\n",
    "        self.init_hidden(torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)), torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)))\n",
    "    \n",
    "    def init_hidden(self, h, c):\n",
    "        self.hidden = (h, c)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text should be of size (T, N, char_dim)\n",
    "        # returns character scores of size (T, N, char_dim)\n",
    "        \n",
    "        hs, self.hidden = self.lstm(text, self.hidden)\n",
    "        char_space = self.hidden2char(hs)\n",
    "        return char_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(model, loss_func, data_fname):\n",
    "    model.lstm.eval()\n",
    "    \n",
    "    # set up csv reader\n",
    "    songfile = open(data_fname, 'r')\n",
    "    csvreader = csv.reader(songfile, delimiter=',')\n",
    "    \n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        model.init_hidden_zeros(1)\n",
    "        for i, row in enumerate(csvreader):\n",
    "            print('\\rOn song %d of validation data' % i, end='')\n",
    "            song = row[1] + '\\n\\n' + row[3]\n",
    "            sequence_in = torch.tensor(char_to_ix([song]), dtype=torch.float)[:-1,:,:]\n",
    "            sequence_out = torch.tensor(char_to_array([song]))[1:,:]\n",
    "            char_scores = model(sequence_in)\n",
    "            losses += [loss_func(char_scores.contiguous().view(-1, char_dim), sequence_out.contiguous().view(-1))]\n",
    "    print()\n",
    "    model.lstm.train()\n",
    "    songfile.close()\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, checkpoint_name=None, minibatch_size=16, optimizer=None):\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    if optimizer == None:\n",
    "        optimizer = optim.RMSprop(model.parameters())\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('on epoch %d' % epoch)\n",
    "        \n",
    "        # set up csv reader\n",
    "        songfile = open('songdata_train.csv', 'r')\n",
    "        csvreader = csv.reader(songfile, delimiter=',')\n",
    "        \n",
    "        epoch_finished = False\n",
    "        minibatch_count = 0\n",
    "        while not epoch_finished:\n",
    "            # read minibatch from file\n",
    "            # StopIteration means the minibatch is finished\n",
    "            songs = []\n",
    "            mb_data_ix = None\n",
    "            mb_data_array = None\n",
    "            try:\n",
    "                for b in range(minibatch_size):\n",
    "                    csvrow = csvreader.__next__()\n",
    "                    songs += [csvrow[1] + '\\n\\n' + csvrow[3]]\n",
    "                    mb_data_ix = torch.tensor(char_to_ix(songs), dtype=torch.float)\n",
    "                    mb_data_array = torch.tensor(char_to_array(songs))\n",
    "            except StopIteration:\n",
    "                \n",
    "                epoch_finished = True\n",
    "                if mb_data_ix is None: # if we read no rows\n",
    "                    break\n",
    "            \n",
    "            minibatch_count += 1\n",
    "            print('\\ron minibatch %d / %d' % (minibatch_count, (train_count - 1) // minibatch_size + 1), end='')\n",
    "            model.zero_grad()\n",
    "\n",
    "            sequence_in = mb_data_ix[:-1, :, :]\n",
    "            sequence_out = mb_data_array[1:, :]\n",
    "\n",
    "            # the last minibatch might have a different size if minibatch_size doesn't evenly divide the number of songs\n",
    "            this_minibatch_size = sequence_in.shape[1]\n",
    "            model.init_hidden_zeros(this_minibatch_size)\n",
    "\n",
    "            char_scores = model(sequence_in)\n",
    "            loss = loss_func(char_scores.contiguous().view(-1, char_dim), sequence_out.contiguous().view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "        print()\n",
    "        songfile.close()\n",
    "        #train_loss = model_loss(model, loss_func, train_data_ix, train_data_array)\n",
    "        #val_loss = model_loss(model, loss_func, val_data_ix, val_data_array)\n",
    "        #print('\\ttraining loss = %f' % train_loss)\n",
    "        #print('\\tvalidation loss = %f' % val_loss)\n",
    "        #train_losses += [train_loss]\n",
    "        #val_losses += [val_loss]\n",
    "        if checkpoint_name != None:\n",
    "            torch.save(model.state_dict(), checkpoint_name + str(epoch))\n",
    "    #return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 0\n",
      "on minibatch 3233 / 3232\n",
      "on epoch 1\n",
      "on minibatch 3233 / 3232\n",
      "on epoch 2\n",
      "on minibatch 3233 / 3232\n",
      "on epoch 3\n",
      "on minibatch 3233 / 3232\n",
      "on epoch 4\n",
      "on minibatch 3233 / 3232\n",
      "on epoch 5\n",
      "on minibatch 1089 / 3232"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-7827577b44db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLyricsLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lyrics_h64_l3_mb16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-162e5bd562b0>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, epochs, checkpoint_name, minibatch_size, optimizer)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_minibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mchar_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7a11a477a492>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# returns character scores of size (T, N, char_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mchar_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchar_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LyricsLSTM(64, 3)\n",
    "train_loop(model, 50, checkpoint_name='lyrics_h64_l3_mb16_epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On song 2872 of validation data\n",
      "for epoch 0, validation loss is 1.403628\n",
      "On song 2872 of validation data\n",
      "for epoch 1, validation loss is 1.352429\n",
      "On song 2872 of validation data\n",
      "for epoch 2, validation loss is 1.330566\n",
      "On song 2872 of validation data\n",
      "for epoch 3, validation loss is 1.315455\n",
      "On song 2872 of validation data\n",
      "for epoch 4, validation loss is nan\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    model = LyricsLSTM(64, 3)\n",
    "    model.load_state_dict(torch.load('lyrics_h64_l3_mb16' + str(epoch)))\n",
    "    val_loss = model_loss(model, torch.nn.CrossEntropyLoss(), 'songdata_val.csv')\n",
    "    print('for epoch %d, validation loss is %f' % (epoch, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Never Once\n",
      "\n",
      "It's the floor in the street  \n",
      "  \n",
      "[Chorus]  \n",
      "  \n",
      "Speak and the sea  \n",
      "Love you on the trees  \n",
      "We are the store  \n",
      "  \n",
      "You have you is gonna dance  \n",
      "The street like you are  \n",
      "  \n",
      "It's the light of your heart  \n",
      "  \n",
      "I want you america  \n",
      "  \n",
      "She hear me see the time  \n",
      "Can you do the curse  \n",
      "  \n",
      "Chotter of me  \n",
      "  \n",
      "I could hell you to keep the way  \n",
      "Every day she hello  \n",
      "I'm gonna get the wall the light  \n",
      "I can't be the delies  \n",
      "It's in the rain  \n",
      "I got your same me  \n",
      "  \n",
      "I want to say the chance  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax()\n",
    "chars = range(128)\n",
    "\n",
    "def sample_char(char_scores, temp):\n",
    "    char_scores = softmax(char_scores / temp)\n",
    "    char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    while not chr(char) in string.printable and char != 0:\n",
    "        char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    return char\n",
    "\n",
    "def sample(model, first_char, init_hidden, T, temp):\n",
    "    model.init_hidden_zeros(1)\n",
    "    result = first_char\n",
    "    cur_char = ord(first_char)\n",
    "    for t in range(T):\n",
    "        one_hot_char = torch.tensor(i128[cur_char], dtype=torch.float).view(1, 1, -1)\n",
    "        char_scores = model(one_hot_char)\n",
    "        cur_char = sample_char(char_scores.view(-1), temp)\n",
    "        if cur_char == 0:\n",
    "            return result\n",
    "        result += chr(cur_char)\n",
    "    return result\n",
    "\n",
    "sampled_song = sample(model, 'N', torch.zeros((1, 1, model.hidden_dim)), 500, 0.5)\n",
    "print(sampled_song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
