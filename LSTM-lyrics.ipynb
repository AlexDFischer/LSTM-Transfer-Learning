{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "# Characters are represented by 1-hot vectors of size 128\n",
    "char_dim = 128\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import string\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LSTM\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 57471\n",
      "training songs:   51724\n",
      "validation songs: 2873\n",
      "test songs:       2874\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "songfile = open('songdata.csv', 'r')\n",
    "songfile.readline()\n",
    "csvreader = csv.reader(songfile, delimiter=',')\n",
    "count = 0\n",
    "while True:\n",
    "    try:\n",
    "        csvreader.__next__()\n",
    "        count += 1\n",
    "    except StopIteration:\n",
    "        break\n",
    "songfile.close()\n",
    "print('count = %d' % count)\n",
    "\n",
    "# randomly assign songs to train, val, and test files\n",
    "perm = np.random.permutation(count)\n",
    "songfile = open('songdata.csv', 'r')\n",
    "songfile.readline()\n",
    "csvreader = csv.reader(songfile, delimiter=',')\n",
    "\n",
    "train_file = open('songdata_train.csv', 'w')\n",
    "val_file = open('songdata_val.csv', 'w')\n",
    "test_file = open('songdata_test.csv', 'w')\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "test_count = 0\n",
    "train_writer = csv.writer(train_file)\n",
    "val_writer = csv.writer(val_file)\n",
    "test_writer = csv.writer(test_file)\n",
    "for i, row in enumerate(csvreader):\n",
    "    if perm[i] < count * 5 // 100:\n",
    "        val_writer.writerow(row)\n",
    "        val_count += 1\n",
    "    elif perm[i] < count * 10 // 100:\n",
    "        test_writer.writerow(row)\n",
    "        test_count += 1\n",
    "    else:\n",
    "        train_writer.writerow(row)\n",
    "        train_count += 1\n",
    "train_file.close()\n",
    "val_file.close()\n",
    "test_file.close()\n",
    "songfile.close()\n",
    "\n",
    "print('training songs:   %d' % train_count)\n",
    "print('validation songs: %d' % val_count)\n",
    "print('test songs:       %d' % test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a list of N strings of length <=T into a numpy array of 1-hot vectors\n",
    "# input: list of length N; max length of any string in the list is T\n",
    "# output size: (T, N, 128)\n",
    "i128 = np.eye(128)\n",
    "def char_to_ix(texts):\n",
    "    T = max([len(text) for text in texts])\n",
    "    ords = np.zeros((T, len(texts)), dtype=int)\n",
    "    for n, text in enumerate(texts):\n",
    "        ords[:len(text), n] = [ord(char) for char in text]\n",
    "    return i128[ords]\n",
    "\n",
    "# converts a list of N strings of length <=T into a numpy array of length (T, N).\n",
    "# Zero-pads shorter strings.\n",
    "def char_to_array(texts):\n",
    "    T = max([len(text) for text in texts])\n",
    "    result = np.zeros((T, len(texts)), dtype=int)\n",
    "    for n, text in enumerate(texts):\n",
    "        result[:len(text), n] = [ord(char) for char in text]\n",
    "    return result\n",
    "    #ords = np.array([[ord(char) for char in text] for text in texts], dtype=int)\n",
    "    #return ords.transpose((1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_stacks):\n",
    "        super(LyricsLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(char_dim, hidden_dim, num_layers=num_stacks, dropout=0.0)\n",
    "        \n",
    "        # The linear layer that maps from hidden state space to character space\n",
    "        self.hidden2char = nn.Linear(hidden_dim, char_dim)\n",
    "        self.init_hidden_zeros(1)\n",
    "    \n",
    "    def init_hidden_zeros(self, minibatch_size):\n",
    "        self.init_hidden(torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)), torch.zeros((self.lstm.num_layers, minibatch_size, self.hidden_dim)))\n",
    "    \n",
    "    def init_hidden(self, h, c):\n",
    "        self.hidden = (h, c)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text should be of size (T, N, char_dim)\n",
    "        # returns character scores of size (T, N, char_dim)\n",
    "        \n",
    "        hs, self.hidden = self.lstm(text, self.hidden)\n",
    "        char_space = self.hidden2char(hs)\n",
    "        return char_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(model, loss_func, data_fname):\n",
    "    model.lstm.eval()\n",
    "    this_minibatch_size = data_ix.shape[1]\n",
    "    model.init_hidden_zeros(this_minibatch_size)\n",
    "    sequence_in = data_ix[:-1, :, :]\n",
    "    #sequence_out = data_array[1:, :]\n",
    "\n",
    "    #char_scores = model(sequence_in)\n",
    "    #loss = loss_func(char_scores.view(-1, char_dim), sequence_out.view(-1))\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, char_in in enumerate(sequence_in):\n",
    "            char_scores = model(char_in.view(1, this_minibatch_size, -1))\n",
    "            loss += loss_func(char_scores.view(-1, char_dim), data_array[i+1,:])\n",
    "    model.lstm.train()\n",
    "    return loss / len(sequence_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, checkpoint_name=None, minibatch_size=16, optimizer=None):\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    if optimizer == None:\n",
    "        optimizer = optim.RMSprop(model.parameters())\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('on epoch %d' % epoch)\n",
    "        \n",
    "        # set up csv reader\n",
    "        songfile = open('songdata_train.csv', 'r')\n",
    "        csvreader = csv.reader(songfile, delimiter=',')\n",
    "        \n",
    "        epoch_finished = False\n",
    "        minibatch_count = 0\n",
    "        while not epoch_finished:\n",
    "            # read minibatch from file\n",
    "            # StopIteration means the minibatch is finished\n",
    "            songs = []\n",
    "            mb_data_ix = None\n",
    "            mb_data_array = None\n",
    "            try:\n",
    "                for b in range(minibatch_size):\n",
    "                    csvrow = csvreader.__next__()\n",
    "                    songs += [csvrow[1] + '\\n\\n' + csvrow[3]]\n",
    "                    mb_data_ix = torch.tensor(char_to_ix(songs), dtype=torch.float)\n",
    "                    mb_data_array = torch.tensor(char_to_array(songs))\n",
    "            except StopIteration:\n",
    "                \n",
    "                epoch_finished = True\n",
    "                if mb_data_ix is None: # if we read no rows\n",
    "                    break\n",
    "            \n",
    "            minibatch_count += 1\n",
    "            print('\\ron minibatch %d / %d' % (minibatch_count, (train_count + 1) // minibatch_size), end='')\n",
    "            model.zero_grad()\n",
    "\n",
    "            sequence_in = mb_data_ix[:-1, :, :]\n",
    "            sequence_out = mb_data_array[1:, :]\n",
    "\n",
    "            # the last minibatch might have a different size if minibatch_size doesn't evenly divide the number of songs\n",
    "            this_minibatch_size = sequence_in.shape[1]\n",
    "            model.init_hidden_zeros(this_minibatch_size)\n",
    "\n",
    "            char_scores = model(sequence_in)\n",
    "            loss = loss_func(char_scores.contiguous().view(-1, char_dim), sequence_out.contiguous().view(-1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "            optimizer.step()\n",
    "        print()\n",
    "        songfile.close()\n",
    "        #train_loss = model_loss(model, loss_func, train_data_ix, train_data_array)\n",
    "        #val_loss = model_loss(model, loss_func, val_data_ix, val_data_array)\n",
    "        #print('\\ttraining loss = %f' % train_loss)\n",
    "        #print('\\tvalidation loss = %f' % val_loss)\n",
    "        #train_losses += [train_loss]\n",
    "        #val_losses += [val_loss]\n",
    "        if checkpoint_name != None:\n",
    "            torch.save(model.state_dict(), checkpoint_name + str(epoch))\n",
    "    #return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on epoch 0\n",
      "on minibatch 13 / 3232"
     ]
    }
   ],
   "source": [
    "model = LyricsLSTM(64, 3)\n",
    "train_loop(model, 50, checkpoint_name='lyrics_h64_l3_mb16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/bin/anaconda3/envs/cs682/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Never Once\n",
      "\n",
      "It's the floor in the street  \n",
      "  \n",
      "[Chorus]  \n",
      "  \n",
      "Speak and the sea  \n",
      "Love you on the trees  \n",
      "We are the store  \n",
      "  \n",
      "You have you is gonna dance  \n",
      "The street like you are  \n",
      "  \n",
      "It's the light of your heart  \n",
      "  \n",
      "I want you america  \n",
      "  \n",
      "She hear me see the time  \n",
      "Can you do the curse  \n",
      "  \n",
      "Chotter of me  \n",
      "  \n",
      "I could hell you to keep the way  \n",
      "Every day she hello  \n",
      "I'm gonna get the wall the light  \n",
      "I can't be the delies  \n",
      "It's in the rain  \n",
      "I got your same me  \n",
      "  \n",
      "I want to say the chance  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax()\n",
    "chars = range(128)\n",
    "\n",
    "def sample_char(char_scores, temp):\n",
    "    char_scores = softmax(char_scores / temp)\n",
    "    char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    while not chr(char) in string.printable and char != 0:\n",
    "        char = np.random.choice(chars, p=char_scores.detach().numpy())\n",
    "    return char\n",
    "\n",
    "def sample(model, first_char, init_hidden, T, temp):\n",
    "    model.init_hidden_zeros(1)\n",
    "    result = first_char\n",
    "    cur_char = ord(first_char)\n",
    "    for t in range(T):\n",
    "        one_hot_char = torch.tensor(i128[cur_char], dtype=torch.float).view(1, 1, -1)\n",
    "        char_scores = model(one_hot_char)\n",
    "        cur_char = sample_char(char_scores.view(-1), temp)\n",
    "        if cur_char == 0:\n",
    "            return result\n",
    "        result += chr(cur_char)\n",
    "    return result\n",
    "\n",
    "sampled_song = sample(model, 'N', torch.zeros((1, 1, model.hidden_dim)), 500, 0.5)\n",
    "print(sampled_song)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
